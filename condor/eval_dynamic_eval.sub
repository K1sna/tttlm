#
# Evaluate dynamic-eval
#

environment = "HF_HOME=/tmp"

tasks = pile_all
world_size = 150
learning_rate = 2e-05
jobdescription = eval-gpt2-large-pile_all-dynamic-eval

executable = /usr/bin/python3
arguments = code/eval_tttlm.py \
            --dynamic_eval \
            --split_text \
            --num_neighbors 20 \
            --rank $(Process) \
            --world_size $(world_size) \
            --tasks $(tasks) \
            --model gpt2-large \
            --tokenizer gpt2-large \
            --max_length 1024 \
            --stride 1024 \
            --learning_rate $(learning_rate) \
            --address_path servers/addresses.txt \
            --results_dir results/$(jobdescription)

output = /home/ysun/retrap/logs/$(jobdescription)_$(Process).out
error  = /home/ysun/retrap/logs/$(jobdescription)_$(Process).err
log    = /home/ysun/retrap/logs/$(jobdescription)_$(Process).log

request_cpus = 4
request_gpus = 1
request_memory = 256000
request_disk   = 60G
requirements = TARGET.CUDAGlobalMemoryMb > 35000

queue $(world_size)